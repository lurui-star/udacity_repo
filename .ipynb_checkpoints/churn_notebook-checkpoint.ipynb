{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d561f9-8772-44a4-8c3e-fdbe292082d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /Users/ruilu/anaconda3/lib/python3.11/site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (1.23.4)\n",
      "Requirement already satisfied: scipy in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (1.3.0)\n",
      "Requirement already satisfied: pandas in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (23.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from numba->shap) (0.40.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from pandas->shap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn->shap) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ruilu/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ruilu/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38891601-8eaf-4c81-9c25-6af626f5e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  packages to install \n",
    "import shap\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea3235f-f4fd-4641-9a26-bd8cc928d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369f9ba-1888-409f-a770-95e16c4b697e",
   "metadata": {},
   "source": [
    "### Step I: import data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e276651-ca89-437b-a98b-3fc064267c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(pth):\n",
    "    '''\n",
    "    returns dataframe for the csv found at pth\n",
    "\n",
    "    input:\n",
    "            pth: a path to the csv\n",
    "    output:\n",
    "            df: pandas dataframe\n",
    "    '''\t\n",
    "    return pd.read_csv(pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e5f104-0667-4fe7-acb9-85b053f1574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_data(pth=\"./data/bank_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d967b022-3005-457a-9571-e1690208845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'Gender',\n",
    "    'Education_Level',\n",
    "    'Marital_Status',\n",
    "    'Income_Category',\n",
    "    'Card_Category']\n",
    "\n",
    "quant_columns = [\n",
    "    'Customer_Age',\n",
    "    'Dependent_count', \n",
    "    'Months_on_book',\n",
    "    'Total_Relationship_Count', \n",
    "    'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon', \n",
    "    'Credit_Limit', \n",
    "    'Total_Revolving_Bal',\n",
    "    'Avg_Open_To_Buy', \n",
    "    'Total_Amt_Chng_Q4_Q1', \n",
    "    'Total_Trans_Amt',\n",
    "    'Total_Trans_Ct', \n",
    "    'Total_Ct_Chng_Q4_Q1', \n",
    "    'Avg_Utilization_Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a688372-ce21-4bbc-8b22-1603a1c48dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df):\n",
    "    '''\n",
    "    perform eda on df and save figures to images folder\n",
    "    input:\n",
    "            df: pandas dataframe\n",
    "\n",
    "    output:\n",
    "            None\n",
    "    '''\n",
    "     # Copy DataFrame\n",
    "    eda_df = df.copy(deep=True)\n",
    "    print(eda_df.shape)\n",
    "    # Check for missing value\n",
    "    missing_values = eda_df.isnull().sum()\n",
    "    print(f\"Check for missing values:\\n{missing_values}\")\n",
    "    # Data summary \n",
    "    eda_df.describe()\n",
    "    # Churn\n",
    "    eda_df['Churn'] = eda_df['Attrition_Flag'].apply(lambda val: 0 if val==\"Existing Customer\" else 1)\n",
    "    # Churn Distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    eda_df['Churn'].hist()\n",
    "    plt.savefig(fname='./images/eda/churn_distribution.png')\n",
    "     # Customer Age Distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    eda_df['Customer_Age'].hist()\n",
    "    plt.savefig(fname='./images/eda/customer_age_distribution.png')\n",
    "\n",
    "    # Marital Status Distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    eda_df.Marital_Status.value_counts('normalize').plot(kind='bar')\n",
    "    plt.savefig(fname='./images/eda/marital_status_distribution.png')\n",
    "\n",
    "    # Total Transaction Distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.histplot(eda_df['Total_Trans_Ct'],kde=True);\n",
    "    plt.savefig(fname='./images/eda/total_transaction_distribution.png')\n",
    "\n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.heatmap(eda_df['quant_columns'].corr(), annot=False, cmap='Dark2_r', linewidths=2)\n",
    "    plt.savefig(fname='./images/eda/heatmap.png')\n",
    "\n",
    "    # Return dataframe\n",
    "    return eda_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3c78b53-d47d-401b-a64f-18e859efb0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10127, 22)\n",
      "Check for missing values:\n",
      "Unnamed: 0                  0\n",
      "CLIENTNUM                   0\n",
      "Attrition_Flag              0\n",
      "Customer_Age                0\n",
      "Gender                      0\n",
      "Dependent_count             0\n",
      "Education_Level             0\n",
      "Marital_Status              0\n",
      "Income_Category             0\n",
      "Card_Category               0\n",
      "Months_on_book              0\n",
      "Total_Relationship_Count    0\n",
      "Months_Inactive_12_mon      0\n",
      "Contacts_Count_12_mon       0\n",
      "Credit_Limit                0\n",
      "Total_Revolving_Bal         0\n",
      "Avg_Open_To_Buy             0\n",
      "Total_Amt_Chng_Q4_Q1        0\n",
      "Total_Trans_Amt             0\n",
      "Total_Trans_Ct              0\n",
      "Total_Ct_Chng_Q4_Q1         0\n",
      "Avg_Utilization_Ratio       0\n",
      "dtype: int64\n",
      "         Unnamed: 0     CLIENTNUM  Customer_Age  Dependent_count  \\\n",
      "count  10127.000000  1.012700e+04  10127.000000     10127.000000   \n",
      "mean    5063.000000  7.391776e+08     46.325960         2.346203   \n",
      "std     2923.557422  3.690378e+07      8.016814         1.298908   \n",
      "min        0.000000  7.080821e+08     26.000000         0.000000   \n",
      "25%     2531.500000  7.130368e+08     41.000000         1.000000   \n",
      "50%     5063.000000  7.179264e+08     46.000000         2.000000   \n",
      "75%     7594.500000  7.731435e+08     52.000000         3.000000   \n",
      "max    10126.000000  8.283431e+08     73.000000         5.000000   \n",
      "\n",
      "       Months_on_book  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
      "count    10127.000000              10127.000000            10127.000000   \n",
      "mean        35.928409                  3.812580                2.341167   \n",
      "std          7.986416                  1.554408                1.010622   \n",
      "min         13.000000                  1.000000                0.000000   \n",
      "25%         31.000000                  3.000000                2.000000   \n",
      "50%         36.000000                  4.000000                2.000000   \n",
      "75%         40.000000                  5.000000                3.000000   \n",
      "max         56.000000                  6.000000                6.000000   \n",
      "\n",
      "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
      "count           10127.000000  10127.000000         10127.000000   \n",
      "mean                2.455317   8631.953698          1162.814061   \n",
      "std                 1.106225   9088.776650           814.987335   \n",
      "min                 0.000000   1438.300000             0.000000   \n",
      "25%                 2.000000   2555.000000           359.000000   \n",
      "50%                 2.000000   4549.000000          1276.000000   \n",
      "75%                 3.000000  11067.500000          1784.000000   \n",
      "max                 6.000000  34516.000000          2517.000000   \n",
      "\n",
      "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
      "count     10127.000000          10127.000000     10127.000000    10127.000000   \n",
      "mean       7469.139637              0.759941      4404.086304       64.858695   \n",
      "std        9090.685324              0.219207      3397.129254       23.472570   \n",
      "min           3.000000              0.000000       510.000000       10.000000   \n",
      "25%        1324.500000              0.631000      2155.500000       45.000000   \n",
      "50%        3474.000000              0.736000      3899.000000       67.000000   \n",
      "75%        9859.000000              0.859000      4741.000000       81.000000   \n",
      "max       34516.000000              3.397000     18484.000000      139.000000   \n",
      "\n",
      "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
      "count         10127.000000           10127.000000  \n",
      "mean              0.712222               0.274894  \n",
      "std               0.238086               0.275691  \n",
      "min               0.000000               0.000000  \n",
      "25%               0.582000               0.023000  \n",
      "50%               0.702000               0.176000  \n",
      "75%               0.818000               0.503000  \n",
      "max               3.714000               0.999000  \n"
     ]
    }
   ],
   "source": [
    "eda_df=perform_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47d93fcc-a61d-4ea5-a5d0-85be59a9292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_helper(dataframe, category_lst, response=None):\n",
    "    '''\n",
    "    Helper function to encode categorical columns with the proportion of churn for each category.\n",
    "    \n",
    "    Input:\n",
    "        dataframe: pandas DataFrame\n",
    "        category_lst: list of columns that contain categorical features\n",
    "        response: string of response name [optional argument for naming variables or index y column]\n",
    "\n",
    "    Output:\n",
    "        pandas DataFrame with new columns containing proportion of churn for each category\n",
    "    '''\n",
    "    \n",
    "    # Copy DataFrame\n",
    "    encoder_df = dataframe.copy(deep=True)\n",
    "\n",
    "    for category in category_lst:\n",
    "        if category not in encoder_df.columns:\n",
    "            raise ValueError(f\"Column '{category}' not found in the DataFrame\")\n",
    "\n",
    "        # Calculate the proportion of churn for each category\n",
    "        column_groups = encoder_df.groupby(category)['Churn'].mean()\n",
    "        \n",
    "        # Map each value in the category column to its churn proportion\n",
    "        encoder_df[category + ('_' + response if response else '')] = encoder_df[category].map(column_groups)\n",
    "    \n",
    "    return encoder_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a0b3b97-fd9f-4efc-b26e-27092942dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_df=encoder_helper(eda_df, cat_columns, 'Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69ea1402-28c8-4468-9552-3dabb9b4f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_engineering(dataframe, response):\n",
    "    '''\n",
    "    input:\n",
    "              data_frame: pandas DataFrame\n",
    "              response: string of response name [optional argument that could be used for\n",
    "                        naming variables or index y column]\n",
    "    output:\n",
    "              X_train: X training data\n",
    "              X_test: X testing data\n",
    "              y_train: y training data\n",
    "              y_test: y testing data\n",
    "    '''\n",
    "    # categorical features\n",
    "    cat_columns = [ 'Gender', 'Education_Level', 'Marital_Status','Income_Category', 'Card_Category'  ]\n",
    "\n",
    "    # feature engineering\n",
    "    encoded_df = encoder_helper(dataframe=dataframe, category_lst=cat_columns, response=response)\n",
    "\n",
    "    # target feature \n",
    "    y = encoded_df['Churn']     \n",
    "\n",
    "    # Create dataframe\n",
    "    X = pd.DataFrame()         \n",
    "\n",
    "    keep_cols = ['Customer_Age', 'Dependent_count', 'Months_on_book',\n",
    "                 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "                 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "                 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "                 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
    "                 'Gender_Churn', 'Education_Level_Churn', 'Marital_Status_Churn',\n",
    "                 'Income_Category_Churn', 'Card_Category_Churn']\n",
    "\n",
    "    # Features DataFrame\n",
    "    X[keep_cols] = encoded_df[keep_cols]\n",
    "\n",
    "    # Train and Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  \n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ead3dd68-ce73-48db-a7d0-7aa6533ab2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineering_df=perform_feature_engineering(encode_df, 'Churn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46eb9f15-a69c-43b8-9c18-a0fd03a278d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_image(y_train,            \n",
    "                                y_test,\n",
    "                                y_train_preds_lr,\n",
    "                                y_train_preds_rf,\n",
    "                                y_test_preds_lr,\n",
    "                                y_test_preds_rf):\n",
    "    '''\n",
    "    Produces classification report for training and testing results and stores report as image\n",
    "    in images folder\n",
    "    input:\n",
    "            y_train: training response values\n",
    "            y_test:  test response values\n",
    "            y_train_preds_lr: training predictions from logistic regression\n",
    "            y_train_preds_rf: training predictions from random forest\n",
    "            y_test_preds_lr: test predictions from logistic regression\n",
    "            y_test_preds_rf: test predictions from random forest\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # RandomForestClassifier \n",
    "    plt.rc('figure', figsize=(6, 6))\n",
    "    plt.text(0.01, 1.25,\n",
    "             str('Random Forest Train'),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.05,\n",
    "             str(classification_report(y_test, y_test_preds_rf)),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.6,\n",
    "             str('Random Forest Test'),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.7,\n",
    "             str(classification_report(y_train, y_train_preds_rf)),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname='./images/results/rf_results.png')\n",
    "\n",
    "    # LogisticRegression \n",
    "    plt.rc('figure', figsize=(6, 6))\n",
    "    plt.text(0.01, 1.25,\n",
    "             str('Logistic Regression Train'),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.05,\n",
    "             str(classification_report(y_train, y_train_preds_lr)),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.6,\n",
    "             str('Logistic Regression Test'),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.text(0.01, 0.7,\n",
    "             str(classification_report(y_test, y_test_preds_lr)),\n",
    "             {'fontsize': 10}, fontproperties='monospace')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname='./images/results/logistic_results.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6558d319-1b4e-49de-8f4e-d5d765c05c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(model, features, output_pth):\n",
    "    '''\n",
    "    Creates and stores the feature importances in pth\n",
    "    input:\n",
    "            model: model object containing feature_importances_\n",
    "            features: pandas dataframe of X values\n",
    "            output_pth: path to store the figure\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "    # Feature importances\n",
    "    importances = model.best_estimator_.feature_importances_\n",
    "\n",
    "    # Sort Feature importances in descending order\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Sorted feature importances\n",
    "    names = [features.columns[i] for i in indices]\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(25, 15))\n",
    "\n",
    "    # Create plot title\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.ylabel('Importance')\n",
    "\n",
    "    # Add bars\n",
    "    plt.bar(range(features.shape[1]), importances[indices])\n",
    "\n",
    "    # x-axis labels\n",
    "    plt.xticks(range(features.shape[1]), names, rotation=90)\n",
    "\n",
    "    # Save the image\n",
    "    plt.savefig(fname=output_pth + 'feature_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db8d5738-6207-471d-96da-14162714c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test):     \n",
    "    '''\n",
    "    Train, store model results: images + scores, and store models\n",
    "    input:\n",
    "              X_train: X training data\n",
    "              X_test: X testing data\n",
    "              y_train: y training data\n",
    "              y_test: y testing data\n",
    "    output:\n",
    "              None\n",
    "    '''\n",
    "    # RandomForestClassifier and LogisticRegression\n",
    "    rfc = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    lrc = LogisticRegression(n_jobs=-1, max_iter=1000)\n",
    "\n",
    "    # Parameters for Grid Search\n",
    "    param_grid = {'n_estimators': [200, 500],\n",
    "                  'max_features': ['auto', 'sqrt'],\n",
    "                  'max_depth' : [4, 5, 100],\n",
    "                  'criterion' :['gini', 'entropy']}\n",
    "\n",
    "    # Grid Search and fit for RandomForestClassifier\n",
    "    cv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "    cv_rfc.fit(X_train, y_train)\n",
    "\n",
    "    # LogisticRegression\n",
    "    lrc.fit(X_train, y_train)\n",
    "\n",
    "    # Save best models\n",
    "    joblib.dump(cv_rfc.best_estimator_, './models/rfc_model.pkl')\n",
    "    joblib.dump(lrc, './models/logistic_model.pkl')\n",
    "\n",
    "    # Compute train and test predictions for RandomForestClassifier\n",
    "    y_train_preds_rf = cv_rfc.best_estimator_.predict(X_train)\n",
    "    y_test_preds_rf  = cv_rfc.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Compute train and test predictions for LogisticRegression\n",
    "    y_train_preds_lr = lrc.predict(X_train)\n",
    "    y_test_preds_lr  = lrc.predict(X_test)\n",
    "\n",
    "    # Compute ROC curve\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    axis = plt.gca()\n",
    "    lrc_plot = RocCurveDisplay.from_estimator(lrc, X_test, y_test, ax=axis, alpha=0.8)                          \n",
    "    rfc_disp = RocCurveDisplay.from_estimator(cv_rfc.best_estimator_, X_test, y_test, ax=axis, alpha=0.8)       \n",
    "    plt.savefig(fname='./images/results/roc_curve_result.png')\n",
    "    #plt.show()\n",
    "\n",
    "    # Compute and results\n",
    "    classification_report_image(y_train, y_test,\n",
    "                                y_train_preds_lr, y_train_preds_rf,\n",
    "                                y_test_preds_lr,  y_test_preds_rf)\n",
    "\n",
    "    # Compute and feature importance\n",
    "    feature_importance_plot(model=cv_rfc,\n",
    "                            features=X_test,\n",
    "                            output_pth='./images/results/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
